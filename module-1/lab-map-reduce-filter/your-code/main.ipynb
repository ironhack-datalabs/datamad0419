{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reduce from functools, numpy and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "location = '../58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the{7}',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own\\nday,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'the',\n",
       " 'city\\nof',\n",
       " 'Orphalese',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'was',\n",
       " 'to\\nreturn',\n",
       " 'and',\n",
       " 'bear',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'isle',\n",
       " 'of\\nhis',\n",
       " 'birth.\\n\\nAnd',\n",
       " 'in',\n",
       " 'the',\n",
       " 'twelfth',\n",
       " 'year,',\n",
       " 'on',\n",
       " 'the',\n",
       " 'seventh\\nday',\n",
       " 'of',\n",
       " 'Ielool,',\n",
       " 'the',\n",
       " 'month',\n",
       " 'of',\n",
       " 'reaping,',\n",
       " 'he\\nclimbed',\n",
       " 'the',\n",
       " 'hill',\n",
       " 'without',\n",
       " 'the',\n",
       " 'city',\n",
       " 'walls\\nand',\n",
       " 'looked',\n",
       " 'seaward;',\n",
       " 'and',\n",
       " 'he',\n",
       " 'beheld',\n",
       " 'his\\nship',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'the',\n",
       " 'mist.\\n\\nThen',\n",
       " 'the',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'were',\n",
       " 'flung\\nopen,',\n",
       " 'and',\n",
       " 'his',\n",
       " 'joy',\n",
       " 'flew',\n",
       " 'far',\n",
       " 'over',\n",
       " 'the',\n",
       " 'sea.\\nAnd',\n",
       " 'he',\n",
       " 'closed',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'prayed',\n",
       " 'in',\n",
       " 'the\\nsilences',\n",
       " 'of',\n",
       " 'his',\n",
       " 'soul.\\n\\n*****\\n\\nBut',\n",
       " 'as',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'the',\n",
       " 'hill,',\n",
       " 'a',\n",
       " 'sadness\\ncame',\n",
       " 'upon',\n",
       " 'him,',\n",
       " 'and',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'in',\n",
       " 'his\\nheart:\\n\\nHow',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'go',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'without\\nsorrow?',\n",
       " 'Nay,',\n",
       " 'not',\n",
       " 'without',\n",
       " 'a',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'the\\nspirit',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'city.',\n",
       " '{8}Long\\nwere',\n",
       " 'the',\n",
       " 'days',\n",
       " 'of',\n",
       " 'pain',\n",
       " 'I',\n",
       " 'have',\n",
       " 'spent\\nwithin',\n",
       " 'its',\n",
       " 'walls,',\n",
       " 'and',\n",
       " 'long',\n",
       " 'were',\n",
       " 'the\\nnights',\n",
       " 'of',\n",
       " 'aloneness;',\n",
       " 'and',\n",
       " 'who',\n",
       " 'can',\n",
       " 'depart\\nfrom',\n",
       " 'his',\n",
       " 'pain',\n",
       " 'and',\n",
       " 'his',\n",
       " 'aloneness',\n",
       " 'without\\nregret?\\n\\nToo',\n",
       " 'many',\n",
       " 'fragments',\n",
       " 'of',\n",
       " 'the',\n",
       " 'spirit',\n",
       " 'have',\n",
       " 'I\\nscattered',\n",
       " 'in',\n",
       " 'these',\n",
       " 'streets,',\n",
       " 'and',\n",
       " 'too',\n",
       " 'many\\nare',\n",
       " 'the',\n",
       " 'children',\n",
       " 'of',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'that',\n",
       " 'walk\\nnaked',\n",
       " 'among',\n",
       " 'these',\n",
       " 'hills,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'cannot\\nwithdraw',\n",
       " 'from',\n",
       " 'them',\n",
       " 'without',\n",
       " 'a',\n",
       " 'burden',\n",
       " 'and\\nan',\n",
       " 'ache.\\n\\nIt',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'garment',\n",
       " 'I',\n",
       " 'cast',\n",
       " 'off',\n",
       " 'this\\nday,',\n",
       " 'but',\n",
       " 'a',\n",
       " 'skin',\n",
       " 'that',\n",
       " 'I',\n",
       " 'tear',\n",
       " 'with',\n",
       " 'my',\n",
       " 'own\\nhands.\\n\\nNor',\n",
       " 'is',\n",
       " 'it',\n",
       " 'a',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'me,\\nbut',\n",
       " 'a',\n",
       " 'heart',\n",
       " 'made',\n",
       " 'sweet',\n",
       " 'with',\n",
       " 'hunger',\n",
       " 'and\\nwith',\n",
       " 'thirst.\\n\\n*****\\n\\nYet',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'tarry',\n",
       " 'longer.\\n\\nThe',\n",
       " 'sea',\n",
       " 'that',\n",
       " 'calls',\n",
       " 'all',\n",
       " 'things',\n",
       " 'unto',\n",
       " 'her\\ncalls',\n",
       " 'me,',\n",
       " 'and',\n",
       " 'I',\n",
       " 'must',\n",
       " 'embark.\\n\\nFor',\n",
       " 'to',\n",
       " 'stay,',\n",
       " 'though',\n",
       " 'the',\n",
       " 'hours',\n",
       " 'burn',\n",
       " 'in\\nthe',\n",
       " 'night,',\n",
       " 'is',\n",
       " 'to',\n",
       " 'freeze',\n",
       " 'and',\n",
       " 'crystallize\\nand',\n",
       " 'be',\n",
       " 'bound',\n",
       " 'in',\n",
       " 'a',\n",
       " 'mould.\\n\\nFain',\n",
       " 'would',\n",
       " 'I',\n",
       " 'take',\n",
       " 'with',\n",
       " 'me',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is\\nhere.',\n",
       " 'But',\n",
       " 'how',\n",
       " 'shall',\n",
       " 'I?\\n\\nA',\n",
       " 'voice',\n",
       " 'cannot',\n",
       " 'carry',\n",
       " 'the',\n",
       " 'tongue',\n",
       " 'and\\n{9}the',\n",
       " 'lips',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'wings.',\n",
       " 'Alone\\nmust',\n",
       " 'it',\n",
       " 'seek',\n",
       " 'the',\n",
       " 'ether.\\n\\nAnd',\n",
       " 'alone',\n",
       " 'and',\n",
       " 'without',\n",
       " 'his',\n",
       " 'nest',\n",
       " 'shall',\n",
       " 'the\\neagle',\n",
       " 'fly',\n",
       " 'across',\n",
       " 'the',\n",
       " 'sun.\\n\\n*****\\n\\nNow',\n",
       " 'when',\n",
       " 'he',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'the\\nhill,',\n",
       " 'he',\n",
       " 'turned',\n",
       " 'again',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'sea,\\nand',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'the\\nharbour,',\n",
       " 'and',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'prow',\n",
       " 'the',\n",
       " 'mariners,\\nthe',\n",
       " 'men',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'land.\\n\\nAnd',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'cried',\n",
       " 'out',\n",
       " 'to',\n",
       " 'them,',\n",
       " 'and',\n",
       " 'he\\nsaid:\\n\\nSons',\n",
       " 'of',\n",
       " 'my',\n",
       " 'ancient',\n",
       " 'mother,',\n",
       " 'you',\n",
       " 'riders',\n",
       " 'of\\nthe',\n",
       " 'tides,\\n\\nHow',\n",
       " 'often',\n",
       " 'have',\n",
       " 'you',\n",
       " 'sailed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'dreams.\\nAnd',\n",
       " 'now',\n",
       " 'you',\n",
       " 'come',\n",
       " 'in',\n",
       " 'my',\n",
       " 'awakening,',\n",
       " 'which\\nis',\n",
       " 'my',\n",
       " 'deeper',\n",
       " 'dream.\\n\\nReady',\n",
       " 'am',\n",
       " 'I',\n",
       " 'to',\n",
       " 'go,',\n",
       " 'and',\n",
       " 'my',\n",
       " 'eagerness',\n",
       " 'with\\nsails',\n",
       " 'full',\n",
       " 'set',\n",
       " 'awaits',\n",
       " 'the',\n",
       " 'wind.\\n\\nOnly',\n",
       " 'another',\n",
       " 'breath',\n",
       " 'will',\n",
       " 'I',\n",
       " 'breathe',\n",
       " 'in\\nthis',\n",
       " 'still',\n",
       " 'air,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'loving',\n",
       " 'look\\ncast',\n",
       " 'backward,\\n\\nAnd',\n",
       " 'then',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'stand',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'a\\nseafarer',\n",
       " 'among',\n",
       " 'seafarers.',\n",
       " '{10}And',\n",
       " 'you,\\nvast',\n",
       " 'sea,',\n",
       " 'sleepless',\n",
       " 'mother,\\n\\nWho',\n",
       " 'alone',\n",
       " 'are',\n",
       " 'peace',\n",
       " 'and',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'the\\nriver',\n",
       " 'and',\n",
       " 'the',\n",
       " 'stream,\\n\\nOnly',\n",
       " 'another',\n",
       " 'winding',\n",
       " 'will',\n",
       " 'this',\n",
       " 'stream\\nmake,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'murmur',\n",
       " 'in',\n",
       " 'this',\n",
       " 'glade,\\n\\nAnd',\n",
       " 'then',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'come',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'a\\nboundless',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'a',\n",
       " 'boundless',\n",
       " 'ocean.\\n\\n*****\\n\\nAnd',\n",
       " 'as',\n",
       " 'he',\n",
       " 'walked',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'afar',\n",
       " 'men\\nand',\n",
       " 'women',\n",
       " 'leaving',\n",
       " 'their',\n",
       " 'fields',\n",
       " 'and',\n",
       " 'their\\nvineyards',\n",
       " 'and',\n",
       " 'hastening',\n",
       " 'towards',\n",
       " 'the',\n",
       " 'city\\ngates.\\n\\nAnd',\n",
       " 'he',\n",
       " 'heard',\n",
       " 'their',\n",
       " 'voices',\n",
       " 'calling',\n",
       " 'his\\nname,',\n",
       " 'and',\n",
       " 'shouting',\n",
       " 'from',\n",
       " 'field',\n",
       " 'to',\n",
       " 'field\\ntelling',\n",
       " 'one',\n",
       " 'another',\n",
       " 'of',\n",
       " 'the',\n",
       " 'coming',\n",
       " 'of',\n",
       " 'his\\nship.\\n\\nAnd',\n",
       " 'he',\n",
       " 'said',\n",
       " 'to',\n",
       " 'himself:\\n\\nShall',\n",
       " 'the',\n",
       " 'day',\n",
       " 'of',\n",
       " 'parting',\n",
       " 'be',\n",
       " 'the',\n",
       " 'day',\n",
       " 'of\\ngathering?\\n\\nAnd',\n",
       " 'shall',\n",
       " 'it',\n",
       " 'be',\n",
       " 'said',\n",
       " 'that',\n",
       " 'my',\n",
       " 'eve',\n",
       " 'was',\n",
       " 'in\\ntruth',\n",
       " 'my',\n",
       " 'dawn?\\n\\nAnd',\n",
       " 'what',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has\\nleft',\n",
       " 'his',\n",
       " 'plough',\n",
       " 'in',\n",
       " 'midfurrow,',\n",
       " 'or',\n",
       " 'to\\nhim',\n",
       " 'who',\n",
       " 'has',\n",
       " 'stopped',\n",
       " 'the',\n",
       " 'wheel',\n",
       " 'of',\n",
       " 'his\\nwinepress?',\n",
       " '{11}Shall',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'become',\n",
       " 'a\\ntree',\n",
       " 'heavy-laden',\n",
       " 'with',\n",
       " 'fruit',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may\\ngather',\n",
       " 'and',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'them?\\n\\nAnd',\n",
       " 'shall',\n",
       " 'my',\n",
       " 'desires',\n",
       " 'flow',\n",
       " 'like',\n",
       " 'a\\nfountain',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'fill',\n",
       " 'their',\n",
       " 'cups?\\n\\nAm',\n",
       " 'I',\n",
       " 'a',\n",
       " 'harp',\n",
       " 'that',\n",
       " 'the',\n",
       " 'hand',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mighty\\nmay',\n",
       " 'touch',\n",
       " 'me,',\n",
       " 'or',\n",
       " 'a',\n",
       " 'flute',\n",
       " 'that',\n",
       " 'his',\n",
       " 'breath\\nmay',\n",
       " 'pass',\n",
       " 'through',\n",
       " 'me?\\n\\nA',\n",
       " 'seeker',\n",
       " 'of',\n",
       " 'silences',\n",
       " 'am',\n",
       " 'I,',\n",
       " 'and',\n",
       " 'what\\ntreasure',\n",
       " 'have',\n",
       " 'I',\n",
       " 'found',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'that',\n",
       " 'I\\nmay',\n",
       " 'dispense',\n",
       " 'with',\n",
       " 'confidence?\\n\\nIf',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'day',\n",
       " 'of',\n",
       " 'harvest,',\n",
       " 'in',\n",
       " 'what\\nfields',\n",
       " 'have',\n",
       " 'I',\n",
       " 'sowed',\n",
       " 'the',\n",
       " 'seed,',\n",
       " 'and',\n",
       " 'in\\nwhat',\n",
       " 'unremembered',\n",
       " 'seasons?\\n\\nIf',\n",
       " 'this',\n",
       " 'indeed',\n",
       " 'be',\n",
       " 'the',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'which',\n",
       " 'I\\nlift',\n",
       " 'up',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'my',\n",
       " 'flame\\nthat',\n",
       " 'shall',\n",
       " 'burn',\n",
       " 'therein.\\n\\nEmpty',\n",
       " 'and',\n",
       " 'dark',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'my',\n",
       " 'lantern,\\n\\nAnd',\n",
       " 'the',\n",
       " 'guardian',\n",
       " 'of',\n",
       " 'the',\n",
       " 'night',\n",
       " 'shall',\n",
       " 'fill\\nit',\n",
       " 'with',\n",
       " 'oil',\n",
       " 'and',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'light',\n",
       " 'it',\n",
       " 'also.\\n\\n*****\\n\\nThese',\n",
       " 'things',\n",
       " 'he',\n",
       " 'said',\n",
       " 'in',\n",
       " 'words.',\n",
       " 'But',\n",
       " 'much\\nin',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'remained',\n",
       " 'unsaid.',\n",
       " 'For',\n",
       " '{12}he\\nhimself',\n",
       " 'could',\n",
       " 'not',\n",
       " 'speak',\n",
       " 'his',\n",
       " 'deeper\\nsecret.\\n\\n*****\\n\\n[Illustration:',\n",
       " '0020]\\n\\nAnd',\n",
       " 'when',\n",
       " 'he',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'the',\n",
       " 'city',\n",
       " 'all\\nthe',\n",
       " 'people',\n",
       " 'came',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'him,',\n",
       " 'and',\n",
       " 'they\\nwere',\n",
       " 'crying',\n",
       " 'out',\n",
       " 'to',\n",
       " 'him',\n",
       " 'as',\n",
       " 'with',\n",
       " 'one\\nvoice.\\n\\nAnd',\n",
       " 'the',\n",
       " 'elders',\n",
       " 'of',\n",
       " 'the',\n",
       " 'city',\n",
       " 'stood',\n",
       " 'forth\\nand',\n",
       " 'said:\\n\\nGo',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'away',\n",
       " 'from',\n",
       " 'us.\\n\\nA',\n",
       " 'noontide',\n",
       " 'have',\n",
       " 'you',\n",
       " 'been',\n",
       " 'in',\n",
       " 'our\\ntwilight,',\n",
       " 'and',\n",
       " 'your',\n",
       " 'youth',\n",
       " 'has',\n",
       " 'given',\n",
       " 'us\\ndreams',\n",
       " 'to',\n",
       " 'dream.\\n\\nNo',\n",
       " 'stranger',\n",
       " 'are',\n",
       " 'you',\n",
       " 'among',\n",
       " 'us,',\n",
       " 'nor\\na',\n",
       " 'guest,',\n",
       " 'but',\n",
       " 'our',\n",
       " 'son',\n",
       " 'and',\n",
       " 'our',\n",
       " 'dearly\\nbeloved.\\n\\nSuffer',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'our',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'hunger',\n",
       " 'for\\nyour',\n",
       " 'face.\\n\\n*****\\n\\nAnd',\n",
       " 'the',\n",
       " 'priests',\n",
       " 'and',\n",
       " 'the',\n",
       " 'priestesses',\n",
       " 'said\\nunto',\n",
       " 'him:\\n\\nLet',\n",
       " 'not',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'separate',\n",
       " 'us\\nnow,',\n",
       " 'and',\n",
       " 'the',\n",
       " 'years',\n",
       " 'you',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'in',\n",
       " 'our\\nmidst',\n",
       " 'become',\n",
       " 'a',\n",
       " 'memory.\\n\\nYou',\n",
       " 'have',\n",
       " 'walked',\n",
       " 'among',\n",
       " 'us',\n",
       " 'a',\n",
       " 'spirit,\\n{13}and',\n",
       " 'your',\n",
       " 'shadow',\n",
       " 'has',\n",
       " 'been',\n",
       " 'a',\n",
       " 'light\\nupon',\n",
       " 'our',\n",
       " 'faces.\\n\\nMuch',\n",
       " 'have',\n",
       " 'we',\n",
       " 'loved',\n",
       " 'you.',\n",
       " 'But',\n",
       " 'speechless\\nwas',\n",
       " 'our',\n",
       " 'love,',\n",
       " 'and',\n",
       " 'with',\n",
       " 'veils',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been\\nveiled.\\n\\nYet',\n",
       " 'now',\n",
       " 'it',\n",
       " 'cries',\n",
       " 'aloud',\n",
       " 'unto',\n",
       " 'you,',\n",
       " 'and\\nwould',\n",
       " 'stand',\n",
       " 'revealed',\n",
       " 'before',\n",
       " 'you.\\n\\nAnd',\n",
       " 'ever',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'that',\n",
       " 'love',\n",
       " 'knows\\nnot',\n",
       " 'its',\n",
       " 'own',\n",
       " 'depth',\n",
       " 'until',\n",
       " 'the',\n",
       " 'hour',\n",
       " 'of\\nseparation.\\n\\n*****\\n\\nAnd',\n",
       " 'others',\n",
       " 'came',\n",
       " 'also',\n",
       " 'and',\n",
       " 'entreated',\n",
       " 'him.\\nBut',\n",
       " 'he',\n",
       " 'answered',\n",
       " 'them',\n",
       " 'not.',\n",
       " 'He',\n",
       " 'only',\n",
       " 'bent\\nhis',\n",
       " 'head;',\n",
       " 'and',\n",
       " 'those',\n",
       " 'who',\n",
       " 'stood',\n",
       " 'near',\n",
       " 'saw\\nhis',\n",
       " 'tears',\n",
       " 'falling',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'breast.\\n\\nAnd',\n",
       " 'he',\n",
       " 'and',\n",
       " 'the',\n",
       " 'people',\n",
       " 'proceeded',\n",
       " 'towards\\nthe',\n",
       " 'great',\n",
       " 'square',\n",
       " 'before',\n",
       " 'the',\n",
       " 'temple.\\n\\nAnd',\n",
       " 'there',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sanctuary',\n",
       " 'a\\nwoman',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'was',\n",
       " 'Almitra.',\n",
       " 'And',\n",
       " 'she\\nwas',\n",
       " 'a',\n",
       " 'seeress.\\n\\nAnd',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'with',\n",
       " 'exceeding\\ntenderness,',\n",
       " 'for',\n",
       " 'it',\n",
       " 'was',\n",
       " 'she',\n",
       " 'who',\n",
       " 'had',\n",
       " 'first\\nsought',\n",
       " 'and',\n",
       " 'believed',\n",
       " 'in',\n",
       " 'him',\n",
       " 'when',\n",
       " 'he',\n",
       " 'had\\nbeen',\n",
       " 'but',\n",
       " 'a',\n",
       " 'day',\n",
       " 'in',\n",
       " 'their',\n",
       " 'city.',\n",
       " '{14}And\\nshe',\n",
       " 'hailed',\n",
       " 'him,',\n",
       " 'saying:\\n\\nProphet',\n",
       " 'of',\n",
       " 'God,',\n",
       " 'in',\n",
       " 'quest',\n",
       " 'of',\n",
       " 'the\\nuttermost,',\n",
       " 'long',\n",
       " 'have',\n",
       " 'you',\n",
       " 'searched',\n",
       " 'the\\ndistances',\n",
       " 'for',\n",
       " 'your',\n",
       " 'ship.\\n\\nAnd',\n",
       " 'now',\n",
       " 'your',\n",
       " 'ship',\n",
       " 'has',\n",
       " 'come,',\n",
       " 'and',\n",
       " 'you',\n",
       " 'must\\nneeds',\n",
       " 'go.\\n\\nDeep',\n",
       " 'is',\n",
       " 'your',\n",
       " 'longing',\n",
       " 'for',\n",
       " 'the',\n",
       " 'land',\n",
       " 'of\\nyour',\n",
       " 'memories',\n",
       " 'and',\n",
       " 'the',\n",
       " 'dwelling',\n",
       " 'place\\nof',\n",
       " 'your',\n",
       " 'greater',\n",
       " 'desires;',\n",
       " 'and',\n",
       " 'our',\n",
       " 'love\\nwould',\n",
       " 'not',\n",
       " 'bind',\n",
       " 'you',\n",
       " 'nor',\n",
       " 'our',\n",
       " 'needs',\n",
       " 'hold\\nyou.\\n\\nYet',\n",
       " 'this',\n",
       " 'we',\n",
       " 'ask',\n",
       " 'ere',\n",
       " 'you',\n",
       " 'leave',\n",
       " 'us,',\n",
       " 'that\\nyou',\n",
       " 'speak',\n",
       " 'to',\n",
       " 'us',\n",
       " 'and',\n",
       " 'give',\n",
       " 'us',\n",
       " 'of',\n",
       " 'your\\ntruth.\\n\\nAnd',\n",
       " 'we',\n",
       " 'will',\n",
       " 'give',\n",
       " 'it',\n",
       " 'unto',\n",
       " 'our',\n",
       " 'children,\\nand',\n",
       " 'they',\n",
       " 'unto',\n",
       " 'their',\n",
       " 'children,',\n",
       " 'and',\n",
       " 'it\\nshall',\n",
       " 'not',\n",
       " 'perish.\\n\\nIn',\n",
       " 'your',\n",
       " 'aloneness',\n",
       " 'you',\n",
       " 'have',\n",
       " 'watched',\n",
       " 'with\\nour',\n",
       " 'days,',\n",
       " 'and',\n",
       " 'in',\n",
       " 'your',\n",
       " 'wakefulness',\n",
       " 'you\\nhave',\n",
       " 'listened',\n",
       " 'to',\n",
       " 'the',\n",
       " 'weeping',\n",
       " 'and',\n",
       " 'the\\nlaughter',\n",
       " 'of',\n",
       " 'our',\n",
       " 'sleep.\\n\\nNow',\n",
       " 'therefore',\n",
       " 'disclose',\n",
       " 'us',\n",
       " 'to',\n",
       " 'ourselves,\\nand',\n",
       " 'tell',\n",
       " 'us',\n",
       " 'all',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'shown\\nyou',\n",
       " 'of',\n",
       " 'that',\n",
       " 'which',\n",
       " 'is',\n",
       " 'between',\n",
       " 'birth',\n",
       " 'and\\ndeath.\\n\\n*****\\n\\nAnd',\n",
       " 'he',\n",
       " 'answered,\\n\\nPeople',\n",
       " 'of',\n",
       " 'Orphalese,',\n",
       " ...]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet = prophet [568:]\n",
    "display (prophet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the{7}',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn',\n",
       " 'unto']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "display(prophet [0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reference(x):\n",
    "    return x.split('{')[0]\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "reference('the{7}')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPHET\\n\\n|Almustafa,', 'the', 'chosen', 'and', 'the\\nbeloved,', 'who', 'was', 'a', 'dawn', 'unto']\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "prophet_reference = list(map(reference, prophet))\n",
    "print(prophet_reference[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'beloved']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def line_break(x):\n",
    "    return x.split('\\n')\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "line_break('the\\nbeloved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PROPHET', '', '|Almustafa,'], ['the'], ['chosen'], ['and'], ['the', 'beloved,'], ['who'], ['was'], ['a'], ['dawn'], ['unto']]\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "prophet_list = list(map(line_break, prophet_reference))\n",
    "print(prophet_list[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPHET', '', '|Almustafa,', 'the', 'chosen', 'and', 'the', 'beloved,', 'who', 'was']\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "prophet_flat = [e for lst in prophet_list for e in lst]\n",
    "print(prophet_flat[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: true if the word is not in the specified list and false if the word is in the list\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # Your code here:\n",
    "    if x in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "print(word_filter('and'), word_filter('John'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET',\n",
       " '',\n",
       " '|Almustafa,',\n",
       " 'chosen',\n",
       " 'beloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own',\n",
       " 'day,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'city',\n",
       " 'of',\n",
       " 'Orphalese']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prophet_filter = list(filter(word_filter, prophet_flat))\n",
    "display(prophet_filter[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Part 1\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n"
     ]
    }
   ],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    if x.lower() in word_list: \n",
    "        return False\n",
    "    else: return True\n",
    "\n",
    "print(word_filter('AND'), word_filter('aN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Smith\n"
     ]
    }
   ],
   "source": [
    "def concat_space(a, b):\n",
    "    return ' '.join([a, b])\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    return ' '.join([a, b])\n",
    "\n",
    "print(concat_space('John', 'Smith'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPHET  |Almustafa, chosen beloved, who was dawn unto his own day, had waited twelve years in city of Orphalese for his ship that was to return bear him back to isle of his birth.  And in twelfth year, on seventh day of Ielool, month of reaping, he climbed hill without city walls looked seaward; he beheld his ship coming with mist.  Then gates of his heart were flung open, his joy flew far over sea. And he closed his eyes prayed in silences of his soul.  *****  But as he descended hill, sadness came upon him, he thought in his heart:  How shall I go in peace without sorrow? Nay, not without wound in spirit shall I leave this city.  days of pain I have spent within its walls, long were nights of aloneness; who can depart from his pain his aloneness without regret?  Too many fragments of spirit have I scattered in these streets, too many are children of my longing that walk naked among these hills, I cannot withdraw from them without burden ache.  It is not garment I cast off this day, \n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "prophet_string = reduce(concat_space, prophet_filter)\n",
    "print (prophet_string[0:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will load a dataset below and then write a function that will perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "# The dataset below contains information about pollution from PM2.5 particles in Beijing \n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "pm25 = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>19.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>21.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>24.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>27.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0\n",
       "5   6  2010      1    1     5    NaN   -19 -10.0  1017.0   NW  16.10   0   0\n",
       "6   7  2010      1    1     6    NaN   -19  -9.0  1017.0   NW  19.23   0   0\n",
       "7   8  2010      1    1     7    NaN   -19  -9.0  1017.0   NW  21.02   0   0\n",
       "8   9  2010      1    1     8    NaN   -19  -9.0  1017.0   NW  24.15   0   0\n",
       "9  10  2010      1    1     9    NaN   -20  -8.0  1017.0   NW  27.28   0   0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "pm25.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def hourly(x):\n",
    "    return (x/24)\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "print(hourly(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.279583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd       Iws   Is  \\\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW  0.074583  0.0   \n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW  0.205000  0.0   \n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW  0.279583  0.0   \n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW  0.410000  0.0   \n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  0.540417  0.0   \n",
       "\n",
       "    Ir  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "pm25[['Iws', 'Is', 'Ir']] = pm25[['Iws', 'Is', 'Ir']].apply(hourly)\n",
    "pm25_hourly = pm25\n",
    "pm25_hourly.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37267799624996495"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_sd(x):\n",
    "    return np.std(x) / (x.count() - 1)\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "sampple_series = pd.Series([1,2,3,4])\n",
    "sample_sd(sampple_series)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
